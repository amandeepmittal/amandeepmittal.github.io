{"componentChunkName":"component---src-templates-post-js","path":"/how-to-build-a-real-time-logo-detection-app-with-react-native-google-vision-api-and-crowdbotics","webpackCompilationHash":"c3a562291cd8e443a353","result":{"data":{"site":{"siteMetadata":{"title":"Aman Mittal - Fullstack Developer","description":"Aman Mittal - Developer and Technical writer.","author":{"name":"Aman Mittal"},"keywords":["Fullstack Developer"]}},"mdx":{"frontmatter":{"title":"How to Build a Real Time Logo Detection App with React Native, Google Vision API and Crowdbotics","date":"March 20, 2019","author":"Aman Mittal","banner":null,"slug":"how-to-build-a-real-time-logo-detection-app-with-react-native-google-vision-api-and-crowdbotics","keywords":null},"code":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"slug\": \"how-to-build-a-real-time-logo-detection-app-with-react-native-google-vision-api-and-crowdbotics\",\n  \"date\": \"2019-03-20T00:00:00.000Z\",\n  \"title\": \"How to Build a Real Time Logo Detection App with React Native, Google Vision API and Crowdbotics\",\n  \"categories\": [\"react native\"],\n  \"description\": \"---\",\n  \"published\": true,\n  \"author\": \"Aman Mittal\",\n  \"banner\": null\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/2560/1*Lxm-nyuRJoEjaH2Skg5SMQ.jpeg\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"Google Vision API is a great way to add image recognition capabilities to your app. It does a great job detecting a variety of categories such as labels, popular logos, faces, landmarks, and text. You can think of Google Vision API as a Google Image Search offered as an API interface that you can incorporate into your applications.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"In this tutorial, you are going to build a React Native application that can identify a picture provided and detect the logo using Google\\u2019s Vision API in real time.\")), mdx(\"p\", null, \"You are going to learn how to connect Google Vision API with React Native and Expo. React Native and Expo will be quickly set up using a predefined scaffold from Crowdbotics. We setup Google Vision API from scratch, and use Firebase cloud storage to store an image that a user uploads. That image is then analyzed before the output is generated.\"), mdx(\"h3\", null, \"Tldr\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Setting up Crowdbotics Project\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Installing dependencies\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Setting up Firebase\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Set up Google Cloud Vision API Key\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Logo Detection App\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Uploading Image to Firebase\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Image picker from Expo\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Analyzing the Logo\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Conclusion\")), mdx(\"h3\", null, \"Setting up Crowdbotics Project\"), mdx(\"p\", null, \"In this section, you will be setting up a Crowdbotics project that has React Native plus Expo pre-defined template with stable and latest dependencies for you to leverage. Setting up a new project using Crowdbotics app builder service is easy. Visit \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://app.crowdbotics.com/vue-dashboard\"\n  }), \"app.crowdbotics.com\"), \" dashboard. Once you are logged in, choose \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Create a new application\"), \".\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*DK_PfPhWHLI4FQVQMzPGbQ.png\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"On the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Create Application\"), \" page, choose \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"React Native Expo\"), \" template under \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Mobile App\"), \".\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*109DBQGNLHmC8lel8OOYmg.png\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"Lastly, choose the name of your template at the bottom of this page and then click the button \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Create by app!\"), \". After a few moments, you will get a similar window like below.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*RSZ9UeCX-ZHM6etmnY5Yuw.png\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"This will take you to the app dashboard, where you can see a link to GitHub, Heroku, and Slack. Once your project is created, you will get an invitation from Crowdbotics to download your project or clone the repository from \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/crowdbotics-apps/rngooglevisionapi-1400\"\n  }), mdx(\"strong\", {\n    parentName: \"a\"\n  }, \"Github\")), \" either on them email you logged in or as a notification if you chose Github authentication.\"), mdx(\"h3\", null, \"Installing dependencies\"), mdx(\"p\", null, \"Once you have cloned or downloaded the repository from Github, traverse inside it using command \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"cd\"), \" or similar from your terminal and install dependencies.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-shell\"\n  }), \"cd rngooglevisionapi-1400\\n\\ncd frontend\\n\\n# Install depenedencies\\n\\nnpm install\\n\")), mdx(\"p\", null, \"Installing dependencies might take a few minutes. Once the step is done\\u200A\\u2014\\u200Adepending on the operating system you have\\u200A\\u2014\\u200Ayou can run the React Native application and verify if everything is working properly using either an iOS simulator or an Android emulator.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-shell\"\n  }), \"# for iOS\\nnpm run ios\\n\\n# for android\\nnpm run android\\n\")), mdx(\"p\", null, \"Android users, note that you must have an Android virtual device already running in order to run the above command successfully.\"), mdx(\"h3\", null, \"Setting up\\xA0Firebase\"), mdx(\"p\", null, \"Using the Firebase project has a lot of advantages over a traditional server API model. It provides the database and the backend service and such that we do not have to write our own backend and host it. Visit \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"http://www.console.firebase.com\"\n  }), \"Firebase.com\"), \" and sign-in with your Google ID. Once logged in, click on a new project and enter a project name. Lastly, hit the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Create Project\"), \" button.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*BDhg-K1-ekeYg4D2AAir3A.jpeg\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"Make sure you set up Firebase real-time database rules to allow the app user to upload image files into the database. To change this setting a newly generated Firebase project, from the sidebar menu in the Firebase console, open Database tab and then choose Rules and modify them as below.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"service cloud.firestore {\\n match /databases/{database}/documents {\\n   match /{document=**} {\\n     allow read, write;\\n   }\\n }\\n}\\n\")), mdx(\"p\", null, \"Next step is to install the Firebase SDK in the project.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-shell\"\n  }), \"npm install --save firebase\\n\")), mdx(\"p\", null, \"To make sure that the required dependency is installed correctly, open \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"package.json\"), \" file. In the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"dependencies\"), \" object you will find many other dependencies related to react, react native navigation, native-base UI kit, redux and so on. These libraries are helpful if you are working on a React Native project that requires feature like a custom and expandable UI kit, state management, navigation.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-json\"\n  }), \"\\\"dependencies\\\": {\\n    \\\"@expo/vector-icons\\\": \\\"^9.0.0\\\",\\n    \\\"expo\\\": \\\"^32.0.0\\\",\\n    \\\"expokit\\\": \\\"^32.0.3\\\",\\n    \\\"firebase\\\": \\\"^5.9.0\\\",\\n    \\\"lodash\\\": \\\"^4.17.11\\\",\\n    \\\"native-base\\\": \\\"^2.10.0\\\",\\n    \\\"prop-types\\\": \\\"^15.6.2\\\",\\n    \\\"react\\\": \\\"16.5.0\\\",\\n    \\\"react-native\\\": \\\"https://github.com/expo/react-native/archive/sdk-32.0.0.tar.gz\\\",\\n    \\\"react-navigation\\\": \\\"^3.0.9\\\",\\n    \\\"react-navigation-redux-helpers\\\": \\\"^2.0.9\\\",\\n    \\\"react-redux\\\": \\\"^6.0.0\\\",\\n    \\\"react-style-proptype\\\": \\\"^3.2.2\\\",\\n    \\\"redux\\\": \\\"^4.0.1\\\",\\n    \\\"redux-thunk\\\": \\\"^2.3.0\\\"\\n  }\\n\")), mdx(\"p\", null, \"You are not going to use the majority of them in this tutorial, but the advantage of \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://crowbotics.com/app-builder\"\n  }), \"Crowdbotics App Builder\"), \" is that it provides a pre-configured and hosted, optimum framework for React Native projects. The unwanted packages can be removed if you do not wish to use them.\"), mdx(\"p\", null, \"After installing the Firebase SDK, create a folder called \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"config\"), \" and inside \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"frontend/src\"), \", and then create a new file called \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"environment.js\"), \". This file will contain all the keys required to bootstrap and hook Firebase SDK within our application.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"var environments = {\\n  staging: {\\n    FIREBASE_API_KEY: 'XXXX',\\n    FIREBASE_AUTH_DOMAIN: 'XXXX',\\n    FIREBASE_DATABASE_URL: 'XXXX',\\n    FIREBASE_PROJECT_ID: 'XXXX',\\n    FIREBASE_STORAGE_BUCKET: 'XXXX',\\n    FIREBASE_MESSAGING_SENDER_ID: 'XXXX',\\n    GOOGLE_CLOUD_VISION_API_KEY: 'XXXX'\\n  },\\n  production: {\\n    // Warning: This file still gets included in your native binary and is not a secure way to store secrets if you build for the app stores. Details: https://github.com/expo/expo/issues/83\\n  }\\n}\\n\\nfunction getReleaseChannel() {\\n  let releaseChannel = Expo.Constants.manifest.releaseChannel\\n  if (releaseChannel === undefined) {\\n    return 'staging'\\n  } else if (releaseChannel === 'staging') {\\n    return 'staging'\\n  } else {\\n    return 'staging'\\n  }\\n}\\nfunction getEnvironment(env) {\\n  console.log('Release Channel: ', getReleaseChannel())\\n  return environments[env]\\n}\\nvar Environment = getEnvironment(getReleaseChannel())\\nexport default Environment\\n\")), mdx(\"p\", null, \"The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Xs\"), \" are the values of each key you have to fill in. Ignore the value for Key \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"GOOGLE_CLOUD_VISION_API_KEY\"), \" for now. Other values for their corresponding keys can be attained from the Firebase console. Visit the Firebase console and then click the gear icon next to Project Overview in the sidebar menu and lastly go to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Project settings\"), \" section.\"), mdx(\"p\", null, \"Then create another file called \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"firebase.js\"), \" inside the config directory. You are going to use this file in the main application later to send requests to upload an image to the Firebase cloud storage. Import \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"environment.js\"), \"in it to access Firebase keys. That's it for this section.\"), mdx(\"h3\", null, \"Set up Google Cloud Vision API\\xA0Key\"), mdx(\"p\", null, \"You need a Gmail account to access the API key for any cloud service provided by Google. Go to \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://cloud.google.com/vision/\"\n  }), \"cloud.google.com\"), \". After you are signed in visit \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://console.cloud.google.com/\"\n  }), \"Google Cloud Console\"), \" and create a new project.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*564hjsW_Z7yQ1QPV5IaJDw.png\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"From the dropdown menu center, select a project. You can click the button \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"New Project\"), \" in the screen below but since we have already generated a Firebase project, select that from the list available.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*BVoAY6JXgqfbBRj0JSpJpg.png\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"Once the project is created or selected, it will appear at the dropdown menu. Next step is to get the Vision API key. Right now you are at the screen called \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Dashboard\"), \" inside the console. From the top left, click on the menu button and a sidebar menu will pop up. Select \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"APIs & Services\"), \" > \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Dashboard\"), \".\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*wqh5sg1lkr8mqVZqVbPEUQ.png\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"At the Dashboard, select the button Enable APIs and Services.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*3SaO3iHEzg8sstWl4lL4og.jpeg\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"Then type \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"vision\"), \" in the search bar as shown below and then click Vision API.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*0Wq-izllTVH_jO17AmSQqg.jpeg\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"Then, click the button \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Enable\"), \" to enable the API. \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Note that\"), \" in order to complete this step of getting the API key, you are required to add billing information to your Google Cloud Platform account.\"), mdx(\"p\", null, \"The URL, in your case, on the dashboard will be similar to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"https://console.cloud.google.com/apis/dashboard?project=FIREBASE-PROJECT-ID&folder&organizationId\"), \". Click on the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Credentials\"), \" section from the left sidebar to create a new API key.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*2WuMEpijqOASZQqUW_mkIQ.jpeg\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"Click the button \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Create Credentials\"), \". Once you have created the API key, it is time to add it in the file \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"environment.js\"), \" in place of the key \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"GOOGLE_CLOUD_VISION_API_KEY\"), \".\"), mdx(\"p\", null, \"The setup is complete. Let us move to the next section and start building the application.\"), mdx(\"h3\", null, \"Logo Detection App\"), mdx(\"p\", null, \"In order to continue building the app, there is another npm module it requires. Run the below command to install it.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-shell\"\n  }), \"npm install --save uuid\\n\")), mdx(\"p\", null, \"This package will help you create a blob for every image that is going to be used for analyzing in the app. A \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"blob\"), \" is a binary large object stored as a single entity in a database. It is common to use blob for multimedia objects such as an image or a video.\"), mdx(\"p\", null, \"Let us start by importing the necessary libraries that we are going to use in our App component. Open \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"App.js\"), \" file and import the following.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"import React, { Component } from 'react'\\nimport {\\n  View,\\n  Text,\\n  StyleSheet,\\n  ScrollView,\\n  ActivityIndicator,\\n  Button,\\n  FlatList,\\n  Clipboard\\n} from 'react-native'\\nimport { ImagePicker, Permissions } from 'expo'\\nimport uuid from 'uuid'\\n\\nimport Environment from './src/config/environment'\\nimport firebase from './src/config/firebase'\\n\")), mdx(\"p\", null, \"Next, inside the class component, define an initial state with three properties.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"class App extends Component {\\n\\n    state = {\\n        image: null,\\n        uploading: false,\\n        googleResponse: null\\n  };\\n\")), mdx(\"p\", null, \"Each property defined above in the state object has an important role in the app. For instance, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"image\"), \" is initialized with a value of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"null\"), \" since when the app starts, there isn't any image URI available by default. The image will be later uploaded to the cloud service. The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"uploading\"), \" is used when an image is being uploaded to the cloud service along with \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ActivityIndicator\"), \" from React Native core. The last property, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"googleResponse\"), \" is going to handle the response object coming back from the Google Vision API when analyzing the data.\"), mdx(\"p\", null, \"It is important to ask for user permissions. Any app functionality that implements features around sensitive information such as location, sending push notifications, taking a picture from the device\\u2019s camera, it needs to ask for permissions. Luckily, when using Expo, it is easier to implement this functionality. After you have initialized the state, use a lifecycle method \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"componentDidMount()\"), \" to ask for permission's to use a device's camera and camera roll (or \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"gallery\"), \" in case of Android).\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"async componentDidMount() {\\n        await Permissions.askAsync(Permissions.CAMERA_ROLL);\\n        await Permissions.askAsync(Permissions.CAMERA);\\n  }\\n\")), mdx(\"p\", null, \"For more information on Permissions with Expo, you should take a look at the \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.expo.io/versions/latest/sdk/permissions/#__next\"\n  }), \"official docs\"), \".\"), mdx(\"p\", null, \"On iOS, asking permissions alert will look like below.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*1IWny3GcKb4iZLQd9MyW0g.png\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"On Android:\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/600/1*u9r_6MpkNUovKzGnRxbh1w.jpeg\",\n    \"alt\": null\n  })), \"\\n\", mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/600/1*OZYu6KqBNfmAn5soM0JqYA.jpeg\",\n    \"alt\": null\n  }))), mdx(\"h3\", null, \"Uploading Images to\\xA0Firebase\"), mdx(\"p\", null, \"To upload file on Firebase cloud storage, you have to create a function outside the class called \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"uploadImageAsync\"), \". This function will handle sending and receiving AJAX requests to the Cloud Storage server. This function is going to be asynchronous.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"async function uploadImageAsync(uri) {\\n  const blob = await new Promise((resolve, reject) => {\\n    const xhr = new XMLHttpRequest()\\n    xhr.onload = function() {\\n      resolve(xhr.response)\\n    }\\n    xhr.onerror = function(e) {\\n      console.log(e)\\n      reject(new TypeError('Network request failed'))\\n    }\\n    xhr.responseType = 'blob'\\n    xhr.open('GET', uri, true)\\n    xhr.send(null)\\n  })\\n\\n  const ref = firebase\\n    .storage()\\n    .ref()\\n    .child(uuid.v4())\\n  const snapshot = await ref.put(blob)\\n\\n  blob.close()\\n\\n  return await snapshot.ref.getDownloadURL()\\n}\\n\")), mdx(\"p\", null, \"This asynchronous function \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"uploadImageAsync\"), \" uploads the image by creating a unique image ID or blob with the help of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"uuid\"), \" module. It also uses \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"xhr\"), \" to send a request to the Firebase Cloud storage to upload the image. It also takes the URI of the image that is going to be uploaded. In the next section, you will learn more about uploading the image.\"), mdx(\"h3\", null, \"Image picker from\\xA0Expo\"), mdx(\"p\", null, \"To access a device\\u2019s UI for selecting an image either from the mobile\\u2019s gallery or take a new picture with the camera, we need an interface for that. Some ready-made, configurable API that allows us to add it as functionality in the app. For this scenario, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ImagePicker\"), \" is available by Expo.\"), mdx(\"p\", null, \"To use this API, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Permissions.CAMERA_ROLL\"), \" is required. Take a look below, how you are going to use it in \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"App.js\"), \" file.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"_takePhoto = async () => {\\n  let pickerResult = await ImagePicker.launchCameraAsync({\\n    allowsEditing: true,\\n    aspect: [4, 3]\\n  })\\n\\n  this._handleImagePicked(pickerResult)\\n}\\n\\n_pickImage = async () => {\\n  let pickerResult = await ImagePicker.launchImageLibraryAsync({\\n    allowsEditing: true,\\n    aspect: [4, 3]\\n  })\\n\\n  this._handleImagePicked(pickerResult)\\n}\\n\\n_handleImagePicked = async pickerResult => {\\n  try {\\n    this.setState({ uploading: true })\\n\\n    if (!pickerResult.cancelled) {\\n      uploadUrl = await uploadImageAsync(pickerResult.uri)\\n      this.setState({ image: uploadUrl })\\n    }\\n  } catch (e) {\\n    console.log(e)\\n    alert('Upload failed, sorry :(')\\n  } finally {\\n    this.setState({ uploading: false })\\n  }\\n}\\n\")), mdx(\"p\", null, \"From the above snippet, notice that there are two separate functions to either pick the image from the device\\u2019s file system: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"_pickImage\"), \" and for taking a photo from the camera: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"_takePhoto\"), \". Whichever function runs, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"_handleImagePicked\"), \" is invoked to upload the file to cloud storage by further calling the asynchronous \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"uploadImageAsync\"), \" function with the URI of the image as the only argument to that function.\"), mdx(\"p\", null, \"Inside the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"render\"), \" function you will add the two buttons calling their own separate methods when pressed.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"<View style={{ margin: 20 }}>\\n    <Button\\n        onPress={this._pickImage}\\n        title=\\\"Pick an image from camera roll\\\"\\n        color=\\\"#3b5998\\\"\\n    />\\n</View>\\n<Button\\nonPress={this._takePhoto}\\ntitle=\\\"Click a photo\\\"\\ncolor=\\\"#1985bc\\\"\\n/>\\n\")), mdx(\"h3\", null, \"Analyzing the\\xA0Logo\"), mdx(\"p\", null, \"After the image has either been selected from the file system or clicked from the camera, it needs to be shared with Google\\u2019s Vision API SDK in order to fetch the result. This is done with the help of a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Button\"), \" component from React Native core in the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"render()\"), \" method inside \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"App.js\"), \".\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"<Button\\n  style={{ marginBottom: 10 }}\\n  onPress={() => this.submitToGoogle()}\\n  title=\\\"Analyze!\\\"\\n/>\\n\")), mdx(\"p\", null, \"This \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Button\"), \" publishes the image to Google's Cloud Vision API. On pressing this button, it calls a separate function \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"submitToGoogle()\"), \" where most of the business logic happens in sending a request and fetching the desired response from the Vision API.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"submitToGoogle = async () => {\\n  try {\\n    this.setState({ uploading: true })\\n    let { image } = this.state\\n    let body = JSON.stringify({\\n      requests: [\\n        {\\n          features: [\\n            { type: 'LABEL_DETECTION', maxResults: 10 },\\n            { type: 'LANDMARK_DETECTION', maxResults: 5 },\\n            { type: 'FACE_DETECTION', maxResults: 5 },\\n            { type: 'LOGO_DETECTION', maxResults: 5 },\\n            { type: 'TEXT_DETECTION', maxResults: 5 },\\n            { type: 'DOCUMENT_TEXT_DETECTION', maxResults: 5 },\\n            { type: 'SAFE_SEARCH_DETECTION', maxResults: 5 },\\n            { type: 'IMAGE_PROPERTIES', maxResults: 5 },\\n            { type: 'CROP_HINTS', maxResults: 5 },\\n            { type: 'WEB_DETECTION', maxResults: 5 }\\n          ],\\n          image: {\\n            source: {\\n              imageUri: image\\n            }\\n          }\\n        }\\n      ]\\n    })\\n    let response = await fetch(\\n      'https://vision.googleapis.com/v1/images:annotate?key=' +\\n        Environment['GOOGLE_CLOUD_VISION_API_KEY'],\\n      {\\n        headers: {\\n          Accept: 'application/json',\\n          'Content-Type': 'application/json'\\n        },\\n        method: 'POST',\\n        body: body\\n      }\\n    )\\n    let responseJson = await response.json()\\n    console.log(responseJson)\\n    this.setState({\\n      googleResponse: responseJson,\\n      uploading: false\\n    })\\n  } catch (error) {\\n    console.log(error)\\n  }\\n}\\n\")), mdx(\"p\", null, \"The Vision API uses an HTTP Post request as a REST API endpoint. It performs data analysis on the image URI send with the request. This is done via the URL \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"https://vision.googleapis.com/v1/images:annotate?key=[API_KEY]\"), \". To authenticate each request, we need the API key. The body of this POST request is in JSON format. This JSON request tells the Google Vision API which image to parse and which of its detection features to enable.\"), mdx(\"p\", null, \"An example a POST body response in JSON format from the API is going to be similar like below.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-json\"\n  }), \"\\\"logoAnnotations\\\": Array [\\n         Object {\\n           \\\"boundingPoly\\\": Object {\\n             \\\"vertices\\\": Array [\\n               Object {\\n                 \\\"x\\\": 993,\\n                 \\\"y\\\": 639,\\n               },\\n               Object {\\n                 \\\"x\\\": 1737,\\n                 \\\"y\\\": 639,\\n               },\\n               Object {\\n                 \\\"x\\\": 1737,\\n                 \\\"y\\\": 1362,\\n               },\\n               Object {\\n                 \\\"x\\\": 993,\\n                 \\\"y\\\": 1362,\\n               },\\n             ],\\n           },\\n           \\\"description\\\": \\\"spotify\\\",\\n           \\\"mid\\\": \\\"/m/04yhd6c\\\",\\n           \\\"score\\\": 0.9259,\\n         },\\n      ],\\n\")), mdx(\"p\", null, \"Notice that it gives us back the complete object with a description of the logo\\u2019s name searched for. This can be viewed in the terminal window from the logs generated while the Expo CLI command is active.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*EJ5MRzjxoBFElHT_1EHbXA.png\",\n    \"alt\": null\n  }))), mdx(\"p\", null, \"See the application in working below. A real android device was used to demonstrate this. If you want to test yourself one a real device, just download the Expo client for your mobile OS, scan the QR code generated after starting expo CLI command and then click the button Take a photo while the application is running.\"), mdx(\"p\", null, \"If you visit the storage section in Firebase, you can notice that each image is stored with a name of base64 binary string.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*jWeopMWFwK7KAoaNPL3dDw.jpeg\",\n    \"alt\": null\n  }))), mdx(\"h3\", null, \"Conclusion\"), mdx(\"p\", null, \"The possibilities of using Google\\u2019s Vision API are endless. As you can see above in the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"features\"), \" array, it works with a variety of categories such as logos, landmarks, labels, documents, human faces and so on.\"), mdx(\"p\", null, \"I hope you enjoyed this tutorial. Let me know if you have any questions.\"), mdx(\"p\", null, \"You can find the complete code in the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Github repository\"), \" below.\"), mdx(\"p\", null, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/crowdbotics-apps/rngooglevisionapi-1400\"\n  }), mdx(\"strong\", {\n    parentName: \"a\"\n  }, \"crowdbotics-apps/rngooglevisionapi-1400\"))), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://medium.com/crowdbotics/how-to-build-a-real-time-logo-detection-app-with-react-native-google-vision-api-and-crowdbotics-9ed65fbcd15\"\n  }), \"Originally published at Crowdbotics\"))));\n}\n;\nMDXContent.isMDXComponent = true;"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"id":"cf6e1e02-a6c4-5eb1-8b24-a118c7b2dc3c","prev":{"id":"5c728967-7c88-5f9e-8e63-1b75dc80ef99","parent":{"name":"index","sourceInstanceName":"blog"},"excerpt":"\nCredits: Unsplash/Joshua Aragon Recently, I was at the Boryspil Airport in Ukraine, working on a blog article, when suddenly my VS Code stopped working. It actually crashed! Not once, but twice in less than 30 minutes. Some of the content was…","fields":{"title":"How I Configure VS Code for Everything","slug":"how-i-configure-vscode-for-everything","date":"2019-03-23T00:00:00.000Z"},"code":{"scope":""}},"next":{"id":"3a771476-8738-5d8d-9179-4de11c049d38","parent":{"name":"index","sourceInstanceName":"blog"},"excerpt":"Tldr; Introduction About styled-components Installing styled-components Using styled-components props  in styled-components Building the app — “Grocery UI” Adding user avatar image Absolute Positioning in React Native Adding icons in a React Native…","fields":{"title":"Using Styled Components with React Native","slug":"using-styled-components-with-react-native","date":"2019-03-19T00:00:00.000Z"},"code":{"scope":""}}}}}